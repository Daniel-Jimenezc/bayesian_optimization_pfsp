{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "incomplete-entity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt import UtilityFunction\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel, ExpSineSquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "transsexual-academy",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PFSP:\n",
    "    def __init__(self):\n",
    "        self.p = None\n",
    "        self.n_jobs = None\n",
    "        self.m_machines = None\n",
    "\n",
    "    def C_init(self, sigma):\n",
    "        c = np.zeros(self.p.shape)\n",
    "        c[0, 0] = self.p[sigma[0], 0]\n",
    "        for i in range(self.n_jobs):\n",
    "            c[i, 0] = self.p[sigma[i], 0] + c[i - 1, 0]\n",
    "        for j in range(self.m_machines):\n",
    "            c[0, j] = self.p[sigma[0], j] + c[0, j - 1]\n",
    "        for i in range(1, self.n_jobs):\n",
    "            for j in range(1, self.m_machines):\n",
    "                c[i, j] = self.p[sigma[i], j] + max(c[i - 1, j], c[i, j - 1])\n",
    "        return c\n",
    "\n",
    "    def F(self, permutation):\n",
    "        summation = 0\n",
    "        c = self.C_init(permutation)\n",
    "        for i in range(len(permutation)):\n",
    "            summation -= c[i, self.m_machines - 1]\n",
    "        return summation\n",
    "\n",
    "    def random_key(self, v):\n",
    "        permutation = np.argsort(v)\n",
    "        return permutation\n",
    "\n",
    "    def black_box_function(self, **kwargs):\n",
    "        data = np.fromiter(kwargs.values(), dtype=float)\n",
    "        permutation = self.random_key(data)\n",
    "        cost = self.F(permutation)\n",
    "        return cost\n",
    "\n",
    "    def read_fsp_file(self, filename):\n",
    "        with open(filename) as f:\n",
    "            content = f.readlines()\n",
    "\n",
    "        # Extract number of jobs and machines from the second line\n",
    "        header = list(map(int, ' '.join(content[1].split()).split()))\n",
    "        n_jobs, m_machines = header[0], header[1]\n",
    "\n",
    "        # Extract the processing times of jobs\n",
    "        p_times_str = content[3:3 + int(m_machines)]\n",
    "        p_matrix = []\n",
    "        for row in p_times_str:\n",
    "            p_matrix.append(list(map(int, ' '.join(row.split()).split())))\n",
    "        p_times = np.matrix(p_matrix).transpose()\n",
    "\n",
    "        return n_jobs, m_machines, p_times\n",
    "\n",
    "    def generate_list_of_files_taillard(self, jobs=(20, 50, 100, 200, 500), machines=(5, 10, 20),\n",
    "                                        instances=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9)):\n",
    "        list_of_files = []\n",
    "        for job in jobs:\n",
    "            for machine in machines:\n",
    "                for instance in instances:\n",
    "                    file = \"taillard_benchmark/tai{}_{}_{}.fsp\".format(job, machine, instance)\n",
    "                    list_of_files.append(file)\n",
    "        return list_of_files\n",
    "\n",
    "    def generate_list_of_files_random(self, jobs=(250, 300, 350, 400, 450), machines=(10, 20),\n",
    "                                      instances=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9)):\n",
    "        list_of_files = []\n",
    "        for job in jobs:\n",
    "            for machine in machines:\n",
    "                for instance in instances:\n",
    "                    file = \"random_benchmark/cebe{}_{}_{}.fsp\".format(job, machine, instance)\n",
    "                    list_of_files.append(file)\n",
    "        return list_of_files\n",
    "\n",
    "    def generate_bounds(self, n, lower_bound=0, upper_bound=1):\n",
    "        i = 0\n",
    "        pbounds = {}\n",
    "        while i < n:\n",
    "            xi = 'x' + str(i)\n",
    "            pbounds[xi] = (lower_bound, upper_bound)\n",
    "            i += 1\n",
    "        return pbounds\n",
    "\n",
    "    def execute_kalimero(self, file, seed, it=1000, nu=2.5, kappa=2.5, xi=0.0):\n",
    "        self.n_jobs, self.m_machines, self.p = self.read_fsp_file(file)\n",
    "        target_results = []\n",
    "        points_results = []\n",
    "\n",
    "        # Bounds of each variable\n",
    "        pbounds = self.generate_bounds(self.n_jobs)\n",
    "\n",
    "        # Bayesian Optimizer\n",
    "        optimizer = BayesianOptimization(\n",
    "            f=None,\n",
    "            pbounds=pbounds,\n",
    "            verbose=2,\n",
    "            random_state=seed,\n",
    "        )\n",
    "\n",
    "        # Kernel\n",
    "        optimizer.set_gp_params(kernel=Matern(nu=nu))\n",
    "\n",
    "        # Adquisition function\n",
    "        utility = UtilityFunction(kind=\"ucb\", kappa=kappa, xi=xi)\n",
    "\n",
    "        # Bayesian Optimization with Gaussian Process\n",
    "        for _ in range(it):\n",
    "            next_point = optimizer.suggest(utility)\n",
    "            target = self.black_box_function(**next_point)\n",
    "            optimizer.register(params=next_point, target=target)\n",
    "            points_results.append(next_point)\n",
    "            target_results.append(int(target))\n",
    "\n",
    "        savefile = 'results/' + file[21:-4]+'__{}_{}_{}'.format(nu,kappa,seed)\n",
    "        row = (file, int(optimizer.max['target']), seed, nu, kappa)\n",
    "        np.save(savefile, row)\n",
    "\n",
    "    def execute(self, file, seed, it=1000, nu=2.5, kappa=2.5, xi=0.0):\n",
    "        self.n_jobs, self.m_machines, self.p = self.read_fsp_file(file)\n",
    "        \n",
    "        # Bounds of each variable\n",
    "        pbounds = self.generate_bounds(self.n_jobs)\n",
    "\n",
    "        # Bayesian Optimizer\n",
    "        optimizer = BayesianOptimization(\n",
    "            f=None,\n",
    "            pbounds=pbounds,\n",
    "            verbose=2,\n",
    "            random_state=seed,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        optimizer.maximize(\n",
    "            init_points=2,\n",
    "            n_iter=it,\n",
    "        )\n",
    "\n",
    "\n",
    "        return res\n",
    "\n",
    "    def execute_taillard_benchmarks(self, jobs=(20, 50, 100, 200, 500), machines=(5, 10, 20),\n",
    "                                    instances=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), seed=0, it=1000):\n",
    "        with open(\"taillard_results.csv\", \"w\") as fp:\n",
    "            writer = csv.writer(fp, delimiter=\",\", lineterminator=\"\\n\")\n",
    "            # writer.writerow([\"your\", \"header\", \"foo\"])  # write header\n",
    "            writer.writerow(['file', 'points_results', 'target_results', 'best_result', 'seed', 'n_it'])\n",
    "        list_of_files = self.generate_list_of_files_taillard(jobs, machines, instances)\n",
    "        for file in list_of_files:\n",
    "            file, points_results, target_results, best_result, seed, it = self.execute(file, seed, it)\n",
    "            # Write CSV file\n",
    "            with open(\"taillard_results.csv\", \"a\") as fp:\n",
    "                writer = csv.writer(fp, delimiter=\",\", lineterminator=\"\\n\")\n",
    "                writer.writerow((file, int(best_result['target']), seed, it))\n",
    "\n",
    "    def execute_random_benchmarks(self, jobs=(250, 300, 350, 400, 450), machines=(10, 20),\n",
    "                                  instances=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9), seed=0, it=1000):\n",
    "        with open(\"random_results.csv\", \"w\") as fp:\n",
    "            writer = csv.writer(fp, delimiter=\",\", lineterminator=\"\\n\")\n",
    "            # writer.writerow([\"your\", \"header\", \"foo\"])  # write header\n",
    "            writer.writerow(['file', 'target_results', 'best_result', 'seed', 'n_it'])\n",
    "        list_of_files = self.generate_list_of_files_random(jobs, machines, instances)\n",
    "        for file in list_of_files:\n",
    "            file, points_results, target_results, best_result, seed, it = self.execute(file, seed, it)\n",
    "            # Write CSV file\n",
    "            with open(\"random_results.csv\", \"a\") as fp:\n",
    "                writer = csv.writer(fp, delimiter=\",\", lineterminator=\"\\n\")\n",
    "                writer.writerow((file, int(best_result['target']), seed, it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "radical-malaysia",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'taillard_benchmark/tai20_5_0.fsp'\n",
    "seed = 0\n",
    "nu = 0.1\n",
    "kappa = 0.01\n",
    "xi = 0.0\n",
    "\n",
    "it = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "sunrise-happiness",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfsp = PFSP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "working-surge",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pfsp.execute_kalimero(file=file, it=it, seed = seed, nu=nu, kappa=kappa, xi=xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-marriage",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesian_optimization",
   "language": "python",
   "name": "bayesian_optimization"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
